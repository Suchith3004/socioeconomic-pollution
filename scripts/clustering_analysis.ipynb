{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "a860ba3d-4d68-47b0-a259-1981268765c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, impute, model_selection, decomposition, cluster, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statistics import mean\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65267d-ef06-42bf-897f-ce51afe16b25",
   "metadata": {},
   "source": [
    "### Import EPA Pollution and Census American Community Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "9be670f0-34af-44fe-a1a4-c58e0e6e5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa = pd.read_csv('../dataset/epa_pollution.csv')\n",
    "census = pd.read_csv('../dataset/census_acs.csv')\n",
    "aqi = pd.read_csv('../dataset/aqi_report.csv')\n",
    "\n",
    "#only use data with common cbsa codes\n",
    "common_cbsa = set(census['cbsa_code'])\n",
    "common_cbsa = common_cbsa.intersection(set(epa['cbsa_code']))\n",
    "common_cbsa = common_cbsa.intersection(set(aqi['cbsa_code']))\n",
    "\n",
    "# Standardized cbsa code datasets\n",
    "epa = epa[epa['cbsa_code'].isin(common_cbsa)].copy()\n",
    "census = census[census['cbsa_code'].isin(common_cbsa)].copy()\n",
    "aqi = aqi[aqi['cbsa_code'].isin(common_cbsa)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec9287-41c2-4faf-9afb-3dcf3387c5b1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c066bf1-6782-446a-952e-956d2b7d4056",
   "metadata": {},
   "source": [
    "### Census ACS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "bae56d0b-66e8-4c7b-8077-ad6ffce2e92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>Less than high school graduate</th>\n",
       "      <th>High school graduate (includes equivalency)</th>\n",
       "      <th>Some college or associate's degree</th>\n",
       "      <th>Bachelor's degree</th>\n",
       "      <th>Graduate or professional degree</th>\n",
       "      <th>$45,000 to $49,999</th>\n",
       "      <th>$50,000 to $59,999</th>\n",
       "      <th>$60,000 to $74,999</th>\n",
       "      <th>$75,000 to $99,999</th>\n",
       "      <th>...</th>\n",
       "      <th>Educational services, and health care and social assistance</th>\n",
       "      <th>Arts, entertainment, and recreation, and accommodation and food services</th>\n",
       "      <th>Other services, except public administration</th>\n",
       "      <th>Public administration</th>\n",
       "      <th>Management, business, science, and arts occupations</th>\n",
       "      <th>Service occupations</th>\n",
       "      <th>Sales and office occupations</th>\n",
       "      <th>Natural resources, construction, and maintenance occupations</th>\n",
       "      <th>Production, transportation, and material moving occupations</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10420</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.342669</td>\n",
       "      <td>0.266596</td>\n",
       "      <td>0.183831</td>\n",
       "      <td>0.097314</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.085722</td>\n",
       "      <td>0.105218</td>\n",
       "      <td>0.116918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224313</td>\n",
       "      <td>0.087933</td>\n",
       "      <td>0.047411</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.341412</td>\n",
       "      <td>0.164147</td>\n",
       "      <td>0.268786</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.223845</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10500</td>\n",
       "      <td>0.214530</td>\n",
       "      <td>0.323630</td>\n",
       "      <td>0.276552</td>\n",
       "      <td>0.115232</td>\n",
       "      <td>0.070055</td>\n",
       "      <td>0.046814</td>\n",
       "      <td>0.099690</td>\n",
       "      <td>0.111882</td>\n",
       "      <td>0.087279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221430</td>\n",
       "      <td>0.066773</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>0.300161</td>\n",
       "      <td>0.138019</td>\n",
       "      <td>0.246350</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10580</td>\n",
       "      <td>0.097922</td>\n",
       "      <td>0.308826</td>\n",
       "      <td>0.284550</td>\n",
       "      <td>0.169404</td>\n",
       "      <td>0.139298</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.137878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259730</td>\n",
       "      <td>0.069128</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.110608</td>\n",
       "      <td>0.397041</td>\n",
       "      <td>0.151805</td>\n",
       "      <td>0.270669</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.178227</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10740</td>\n",
       "      <td>0.140155</td>\n",
       "      <td>0.265774</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.169377</td>\n",
       "      <td>0.130775</td>\n",
       "      <td>0.043810</td>\n",
       "      <td>0.083659</td>\n",
       "      <td>0.113831</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223604</td>\n",
       "      <td>0.094226</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.063296</td>\n",
       "      <td>0.374627</td>\n",
       "      <td>0.166710</td>\n",
       "      <td>0.264363</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.192294</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10780</td>\n",
       "      <td>0.176673</td>\n",
       "      <td>0.371108</td>\n",
       "      <td>0.262197</td>\n",
       "      <td>0.136293</td>\n",
       "      <td>0.053729</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.072454</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>0.091749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302493</td>\n",
       "      <td>0.063796</td>\n",
       "      <td>0.038255</td>\n",
       "      <td>0.085138</td>\n",
       "      <td>0.334400</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>0.256644</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.231201</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cbsa_code  Less than high school graduate  \\\n",
       "1      10420                        0.109590   \n",
       "2      10500                        0.214530   \n",
       "3      10580                        0.097922   \n",
       "4      10740                        0.140155   \n",
       "5      10780                        0.176673   \n",
       "\n",
       "   High school graduate (includes equivalency)  \\\n",
       "1                                     0.342669   \n",
       "2                                     0.323630   \n",
       "3                                     0.308826   \n",
       "4                                     0.265774   \n",
       "5                                     0.371108   \n",
       "\n",
       "   Some college or associate's degree  Bachelor's degree  \\\n",
       "1                            0.266596           0.183831   \n",
       "2                            0.276552           0.115232   \n",
       "3                            0.284550           0.169404   \n",
       "4                            0.293919           0.169377   \n",
       "5                            0.262197           0.136293   \n",
       "\n",
       "   Graduate or professional degree  $45,000 to $49,999  $50,000 to $59,999  \\\n",
       "1                         0.097314            0.043547            0.085722   \n",
       "2                         0.070055            0.046814            0.099690   \n",
       "3                         0.139298            0.046200            0.092376   \n",
       "4                         0.130775            0.043810            0.083659   \n",
       "5                         0.053729            0.041082            0.072454   \n",
       "\n",
       "   $60,000 to $74,999  $75,000 to $99,999  ...  \\\n",
       "1            0.105218            0.116918  ...   \n",
       "2            0.111882            0.087279  ...   \n",
       "3            0.111600            0.137878  ...   \n",
       "4            0.113831            0.102810  ...   \n",
       "5            0.070793            0.091749  ...   \n",
       "\n",
       "   Educational services, and health care and social assistance  \\\n",
       "1                                           0.224313             \n",
       "2                                           0.221430             \n",
       "3                                           0.259730             \n",
       "4                                           0.223604             \n",
       "5                                           0.302493             \n",
       "\n",
       "   Arts, entertainment, and recreation, and accommodation and food services  \\\n",
       "1                                           0.087933                          \n",
       "2                                           0.066773                          \n",
       "3                                           0.069128                          \n",
       "4                                           0.094226                          \n",
       "5                                           0.063796                          \n",
       "\n",
       "   Other services, except public administration  Public administration  \\\n",
       "1                                      0.047411               0.029834   \n",
       "2                                      0.066212               0.076664   \n",
       "3                                      0.038137               0.110608   \n",
       "4                                      0.045499               0.063296   \n",
       "5                                      0.038255               0.085138   \n",
       "\n",
       "   Management, business, science, and arts occupations  Service occupations  \\\n",
       "1                                           0.341412               0.164147   \n",
       "2                                           0.300161               0.138019   \n",
       "3                                           0.397041               0.151805   \n",
       "4                                           0.374627               0.166710   \n",
       "5                                           0.334400               0.170620   \n",
       "\n",
       "   Sales and office occupations  \\\n",
       "1                      0.268786   \n",
       "2                      0.246350   \n",
       "3                      0.270669   \n",
       "4                      0.264363   \n",
       "5                      0.256644   \n",
       "\n",
       "   Natural resources, construction, and maintenance occupations  \\\n",
       "1                                           0.001810              \n",
       "2                                           0.009773              \n",
       "3                                           0.002259              \n",
       "4                                           0.002006              \n",
       "5                                           0.007136              \n",
       "\n",
       "   Production, transportation, and material moving occupations  year  \n",
       "1                                           0.223845            2005  \n",
       "2                                           0.305697            2005  \n",
       "3                                           0.178227            2005  \n",
       "4                                           0.192294            2005  \n",
       "5                                           0.231201            2005  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove redundant/irrelevant columns\n",
    "census = census.drop(['metropolitan_area', 'city', 'state'], axis=1)\n",
    "\n",
    "# Normalize columns\n",
    "# Income\n",
    "income = [i for i in census.columns if '$' in i]\n",
    "for col in income:\n",
    "    census[col] = census[col]/census['Income_Total']\n",
    "census.drop('Income_Total', axis=1, inplace=True)\n",
    "\n",
    "#Education\n",
    "education = [i for i in census.columns if ('degree' in i) or ('graduate' in i)]\n",
    "for col in education:\n",
    "    census[col] = census[col]/census['Education_Total']\n",
    "census.drop('Education_Total', axis=1, inplace=True)\n",
    "\n",
    "# Occupation\n",
    "occupation = [i for i in census.columns if (i not in income) and (i not in education) and (i not in ['cbsa_code', 'year', 'Occupation_Total'])]\n",
    "for col in occupation:\n",
    "    census[col] = census[col]/census['Occupation_Total']\n",
    "census.drop('Occupation_Total', axis=1, inplace=True)\n",
    "\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "94ae6f1a-d76d-482b-a80e-65e8052a7c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4644, 33)"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "a609b2c0-e521-49c6-a3a8-62e1605f9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_econ = census"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebde65-8de3-4f08-8b8b-db2e4df62e58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c242a5-21bf-4eb9-a134-57c5da80cdf2",
   "metadata": {},
   "source": [
    "Since there are 33 attributes and only 5K instances, it may not be sufficient for a successful clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "3a676c76-aec0-4d0f-b029-6de9270daa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4644, 11)"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Capture 90% variance \n",
    "pca = decomposition.PCA(n_components=.90, svd_solver='full')\n",
    "\n",
    "#only apply PCA on the continious variables \n",
    "continuous = census.drop(['cbsa_code', 'year'], axis=1)\n",
    "reduced_census = pd.DataFrame(pca.fit_transform(continuous))\n",
    "reduced_census['cbsa_code'] = census['cbsa_code']\n",
    "reduced_census['year'] = census['year']\n",
    "\n",
    "census_df = reduced_census.sort_values(['cbsa_code', 'year'], axis=0)\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02a843-7876-49ed-9f91-ff01f84cf6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean AQI Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "155415b1-6722-481f-91ef-a9632b10eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "for year in aqi['year'].unique():\n",
    "    for cbsa in aqi['cbsa_code'].unique():\n",
    "        curr = aqi[(aqi['year'] == year) & (aqi['cbsa_code'] == cbsa)]\n",
    "        if curr.shape[0] > 0:\n",
    "            temp_df = temp_df.append(curr.iloc[0,:], ignore_index=True)\n",
    "aqi = temp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "1fe9eab8-9763-4d28-b243-e73498c6b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the days for each air quality with the total AQI days\n",
    "qualities = ['Good', 'Moderate', 'Unhealthy for Sensitive Groups', 'Unhealthy', 'Very Unhealthy']\n",
    "for quality in qualities:\n",
    "    aqi.loc[:, quality] = aqi[quality] / aqi['# Days with AQI']\n",
    "    \n",
    "aqi.sort_values(['cbsa_code', 'year'], inplace=True, axis=0)\n",
    "aqi.drop(columns=\"# Days with AQI\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea556bc9-b8cb-4ac7-992b-2535a0f6fb42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EPA Pollution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8021317-314b-43d0-9ef2-29d3d5bfe8c2",
   "metadata": {},
   "source": [
    "Clean up data such that each instance contains all pollutants for each cbsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "083b805e-f575-4832-8862-59786334eae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "durations = ['1 HOUR','24-HR BLK AVG', '24 HOUR', '3-HR BLK AVG', '8-HR RUN AVG END HOUR', '8-HR RUN AVG BEGIN HOUR', '5 MINUTE', 'INTEGRATED PASSIVE 4-WEEKS', 'INTEGREATED PASSIVE 3-WEEKS']\n",
    "first_duration = {'PM2.5': '1 HOUR',\n",
    "                  'Ozone': '8-HR RUN AVG END HOUR',\n",
    "                  'Carbon_monoxide': '1 HOUR',\n",
    "                  'Sulfur_dioxide': '1 HOUR'}\n",
    "\n",
    "## Create new pollution DF with all the pollutants for every instance\n",
    "pollution_df = pd.DataFrame()\n",
    "for year in range(2005, 2020):\n",
    "    for code in common_cbsa:\n",
    "        new_row = {'year': year,\n",
    "                   'cbsa_code': code}\n",
    "\n",
    "        #average all records for year and code into one instance\n",
    "        for k, v in first_duration.items():\n",
    "            pollutant = pollution[(pollution['year'] == year) & (pollution['cbsa_code'] == code) & (pollution['parameter'].str.contains(k.replace('_', ' ')))]\n",
    "            avg_poll = pollutant[pollutant['sample_duration'] == v]\n",
    "            new_row[k + '_sample_duration'] = v\n",
    "            \n",
    "            #If no instances matching the sample duration exist, then we look for other\n",
    "            for duration in durations:\n",
    "                if avg_poll.shape[0] != 0: break\n",
    "                avg_poll = pollutant[pollutant['sample_duration'] == duration]\n",
    "                new_row[k + '_sample_duration'] = duration\n",
    "            \n",
    "            if avg_poll.shape[0] == 0: \n",
    "                new_row[k + '_sample_duration'] = np.nan\n",
    "            \n",
    "            attributes = ['arithmetic_mean', 'standard_deviation', 'ninety_ninth_percentile', 'seventy_fifth_percentile']\n",
    "            for attr in attributes:\n",
    "                new_row[k + '_' + attr] = pollutant[attr].mean()\n",
    "\n",
    "        # Add matching AQI report to index\n",
    "        aqi_dict = aqi[(aqi['cbsa_code'] == code) & (aqi['year'] == year)]\n",
    "        for col in aqi_dict.columns:\n",
    "            if col != 'year' and col != 'cbsa_code':\n",
    "                new_row[col] = aqi_dict.iloc[0, :][col] if (aqi_dict.shape[0] != 0) else None\n",
    "                \n",
    "        pollution_df = pollution_df.append(new_row, ignore_index=True)\n",
    "        \n",
    "pollution_df.sort_values(['cbsa_code', 'year'], inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7e0e4-30a6-4e8e-ab29-7e907147b5b5",
   "metadata": {},
   "source": [
    "#### Fill and Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b3adab3c-f290-4a25-a9a1-f37577fe4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nan pollution values with recent year values\n",
    "for code in common_cbsa:\n",
    "    pollution_df[pollution_df['cbsa_code'] == code] = pollution_df[pollution_df['cbsa_code'] == code].fillna(method='ffill', axis=0) ## Fill forward to bring last completed year forward\n",
    "    pollution_df[pollution_df['cbsa_code'] == code] = pollution_df[pollution_df['cbsa_code'] == code].fillna(method='bfill', axis=0) ## Fill backward to impute missing values in earlier years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "60d913d0-0646-4b4d-8dca-18ea1b20cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Impute sample duration with mode\n",
    "si = impute.SimpleImputer( strategy='most_frequent')\n",
    "dur_labels = [col for col in pollution_df.columns if 'duration' in col]\n",
    "pollution_df[dur_labels] = si.fit_transform(pollution_df[dur_labels])\n",
    "\n",
    "# Label encode all sample_duration columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(durations)\n",
    "for col in dur_labels:\n",
    "    pollution_df[col] = le.transform(pollution_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "aacf69dd-d763-45ba-9e09-597fa44ea85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in remaining values with average\n",
    "si = impute.SimpleImputer()\n",
    "pollution_df = pd.DataFrame(si.fit_transform(pollution_df), columns=pollution_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a3af6466-463b-4b9f-aef1-84404b68df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution_df.sort_values(['cbsa_code', 'year'], inplace=True, axis=0)\n",
    "pollution_df.to_csv('../dataset/epa_pollution_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9e7db2b1-bae0-4833-9dcd-fc0b2fe4e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_poll = pollution_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839b4b3-05c1-41e2-8117-c65a895ae1fd",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79e279-5fa8-4020-9f2f-eec1e7606ee7",
   "metadata": {},
   "source": [
    "Since there are 33 attributes and only 5K instances, it may not be sufficient for a successful clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "14d9a67a-eff6-42f0-94eb-507e5b5aafc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5085, 10)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Capture 90% variance \n",
    "pca = decomposition.PCA(n_components=.90, svd_solver='full')\n",
    "\n",
    "#only apply PCA on the continious variables \n",
    "continuous = pollution_df.drop(['cbsa_code', 'year'], axis=1)\n",
    "continuous = continuous.drop(dur_labels, axis=1)\n",
    "reduced_epa = pd.DataFrame(pca.fit_transform(continuous))\n",
    "reduced_epa['cbsa_code'] = pollution_df['cbsa_code']\n",
    "reduced_epa['year'] = pollution_df['year']\n",
    "for duration in dur_labels:\n",
    "    reduced_epa[duration] = pollution_df[duration]\n",
    "\n",
    "reduced_epa.sort_values(['cbsa_code', 'year'], inplace=True, axis=0)\n",
    "# reduced_epa.to_csv('../dataset/epa_pollution_clean.csv', index=False)\n",
    "reduced_epa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5f889513-764a-4941-8d57-bb0a748a9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_poll = reduced_epa.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4facb03-a8bd-4d29-9157-6c84f924d2cb",
   "metadata": {},
   "source": [
    "## Symbol Encoding with Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184b62d-1829-4d16-8616-04956596c0a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### K-Means clustering on EPA pollution + AQI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b47b5862-1010-43fa-ac5c-dcc1e7e3a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1673: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmm = cluster.KMeans(n_clusters=5, random_state=27)\n",
    "kmm.fit_predict(reduced_epa.drop(columns=['year', 'cbsa_code']))\n",
    "reduced_epa['cluster'] = kmm.labels_\n",
    "reduced_epa.to_csv('../dataset/epa_aqi_clustered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad76d5f-7e94-4352-9c27-a5f50eb1f1d0",
   "metadata": {},
   "source": [
    "### K-Means clustering on AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "3e6c1923-7253-4e43-8388-12a680f84b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmm = cluster.KMeans(n_clusters=4, random_state=27)\n",
    "kmm.fit_predict(aqi.drop(columns=['cbsa_code', 'year']))\n",
    "aqi['cluster'] = kmm.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371f055-06a7-4659-93f1-e3e47e5ad109",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K-Means clustering on ACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "aea60ec6-36af-4b42-908c-3f3f35099bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmm = cluster.KMeans(n_clusters=4, random_state=27)\n",
    "kmm.fit_predict(census.drop(columns=['cbsa_code', 'year']))\n",
    "census['cluster'] = kmm.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e0840-f2ba-4315-968f-4e12132e6d53",
   "metadata": {},
   "source": [
    "### Explore clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "1056e264-190d-4c49-8d4b-bc34f9796b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 0.0, 1.0, 2.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Good</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Unhealthy for Sensitive Groups</th>\n",
       "      <th>Unhealthy</th>\n",
       "      <th>Very Unhealthy</th>\n",
       "      <th>AQI Maximum</th>\n",
       "      <th>AQI 90th Percentile</th>\n",
       "      <th>AQI Median</th>\n",
       "      <th># Days CO</th>\n",
       "      <th># Days NO2</th>\n",
       "      <th># Days O3</th>\n",
       "      <th># Days SO2</th>\n",
       "      <th># Days PM2.5</th>\n",
       "      <th># Days PM10</th>\n",
       "      <th>year</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242374</td>\n",
       "      <td>0.543107</td>\n",
       "      <td>0.145288</td>\n",
       "      <td>0.042018</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>918.562500</td>\n",
       "      <td>123.781250</td>\n",
       "      <td>72.093750</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>10.031250</td>\n",
       "      <td>167.375000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>65.781250</td>\n",
       "      <td>121.718750</td>\n",
       "      <td>2012.625000</td>\n",
       "      <td>34615.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.601384</td>\n",
       "      <td>0.349931</td>\n",
       "      <td>0.040371</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>140.467883</td>\n",
       "      <td>76.870936</td>\n",
       "      <td>46.192308</td>\n",
       "      <td>0.920698</td>\n",
       "      <td>6.788263</td>\n",
       "      <td>135.034496</td>\n",
       "      <td>19.115781</td>\n",
       "      <td>175.053925</td>\n",
       "      <td>8.193894</td>\n",
       "      <td>2011.824742</td>\n",
       "      <td>29771.399683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746566</td>\n",
       "      <td>0.223919</td>\n",
       "      <td>0.025809</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>129.063373</td>\n",
       "      <td>68.795381</td>\n",
       "      <td>41.793233</td>\n",
       "      <td>1.206230</td>\n",
       "      <td>6.737379</td>\n",
       "      <td>256.670247</td>\n",
       "      <td>6.320086</td>\n",
       "      <td>57.780344</td>\n",
       "      <td>8.532223</td>\n",
       "      <td>2012.114930</td>\n",
       "      <td>30608.002148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.709537</td>\n",
       "      <td>0.277597</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>119.772549</td>\n",
       "      <td>62.043137</td>\n",
       "      <td>36.170588</td>\n",
       "      <td>0.837255</td>\n",
       "      <td>0.409804</td>\n",
       "      <td>20.358824</td>\n",
       "      <td>3.490196</td>\n",
       "      <td>322.664706</td>\n",
       "      <td>5.123529</td>\n",
       "      <td>2012.135294</td>\n",
       "      <td>30364.666667</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Good  Moderate  Unhealthy for Sensitive Groups  Unhealthy  \\\n",
       "3  0.242374  0.543107                        0.145288   0.042018   \n",
       "0  0.601384  0.349931                        0.040371   0.007768   \n",
       "2  0.746566  0.223919                        0.025809   0.003388   \n",
       "1  0.709537  0.277597                        0.010186   0.002403   \n",
       "\n",
       "   Very Unhealthy  AQI Maximum  AQI 90th Percentile  AQI Median  # Days CO  \\\n",
       "3        0.027213   918.562500           123.781250   72.093750   0.281250   \n",
       "0        0.000546   140.467883            76.870936   46.192308   0.920698   \n",
       "2        0.000318   129.063373            68.795381   41.793233   1.206230   \n",
       "1        0.000276   119.772549            62.043137   36.170588   0.837255   \n",
       "\n",
       "   # Days NO2   # Days O3  # Days SO2  # Days PM2.5  # Days PM10         year  \\\n",
       "3   10.031250  167.375000    0.062500     65.781250   121.718750  2012.625000   \n",
       "0    6.788263  135.034496   19.115781    175.053925     8.193894  2011.824742   \n",
       "2    6.737379  256.670247    6.320086     57.780344     8.532223  2012.114930   \n",
       "1    0.409804   20.358824    3.490196    322.664706     5.123529  2012.135294   \n",
       "\n",
       "      cbsa_code  cluster  \n",
       "3  34615.000000      3.0  \n",
       "0  29771.399683      0.0  \n",
       "2  30608.002148      1.0  \n",
       "1  30364.666667      2.0  "
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.DataFrame()\n",
    "for clus in aqi['cluster'].unique():\n",
    "    new_row = dict()\n",
    "    cluster_aqi = aqi[aqi['cluster'] == clus]\n",
    "    for col in cluster_aqi:\n",
    "        new_row[col] = cluster_aqi[col].mean()\n",
    "        \n",
    "    cluster_info = cluster_info.append(new_row, ignore_index=True)\n",
    "    \n",
    "cluster_info.sort_values(['Unhealthy for Sensitive Groups'], inplace=True, axis=0, ascending=False)\n",
    "aqi_clusters = list(cluster_info['cluster'])\n",
    "print(aqi_clusters)\n",
    "cluster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "fbbf7f51-2ef7-42a1-943e-3e75413f6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 1.0, 2.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>Less than high school graduate</th>\n",
       "      <th>High school graduate (includes equivalency)</th>\n",
       "      <th>Some college or associate's degree</th>\n",
       "      <th>Bachelor's degree</th>\n",
       "      <th>Graduate or professional degree</th>\n",
       "      <th>$45,000 to $49,999</th>\n",
       "      <th>$50,000 to $59,999</th>\n",
       "      <th>$60,000 to $74,999</th>\n",
       "      <th>$75,000 to $99,999</th>\n",
       "      <th>...</th>\n",
       "      <th>Arts, entertainment, and recreation, and accommodation and food services</th>\n",
       "      <th>Other services, except public administration</th>\n",
       "      <th>Public administration</th>\n",
       "      <th>Management, business, science, and arts occupations</th>\n",
       "      <th>Service occupations</th>\n",
       "      <th>Sales and office occupations</th>\n",
       "      <th>Natural resources, construction, and maintenance occupations</th>\n",
       "      <th>Production, transportation, and material moving occupations</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33398.971061</td>\n",
       "      <td>0.269497</td>\n",
       "      <td>0.264994</td>\n",
       "      <td>0.295122</td>\n",
       "      <td>0.113690</td>\n",
       "      <td>0.056697</td>\n",
       "      <td>0.044216</td>\n",
       "      <td>0.079339</td>\n",
       "      <td>0.099198</td>\n",
       "      <td>0.109377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087788</td>\n",
       "      <td>0.048292</td>\n",
       "      <td>0.060979</td>\n",
       "      <td>0.267799</td>\n",
       "      <td>0.199264</td>\n",
       "      <td>0.233179</td>\n",
       "      <td>0.135198</td>\n",
       "      <td>0.164559</td>\n",
       "      <td>2012.446945</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30685.978947</td>\n",
       "      <td>0.144340</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.291058</td>\n",
       "      <td>0.140612</td>\n",
       "      <td>0.075539</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>0.087576</td>\n",
       "      <td>0.106588</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086827</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>0.042181</td>\n",
       "      <td>0.304924</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.246849</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>0.232181</td>\n",
       "      <td>2009.835789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29970.060729</td>\n",
       "      <td>0.114530</td>\n",
       "      <td>0.288332</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>0.174134</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>0.044449</td>\n",
       "      <td>0.083649</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.122861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104871</td>\n",
       "      <td>0.048654</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>0.345032</td>\n",
       "      <td>0.189879</td>\n",
       "      <td>0.246689</td>\n",
       "      <td>0.081240</td>\n",
       "      <td>0.137159</td>\n",
       "      <td>2013.106275</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28550.032189</td>\n",
       "      <td>0.093346</td>\n",
       "      <td>0.231343</td>\n",
       "      <td>0.278355</td>\n",
       "      <td>0.232685</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.075953</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.128104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095645</td>\n",
       "      <td>0.046582</td>\n",
       "      <td>0.048712</td>\n",
       "      <td>0.428895</td>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.224407</td>\n",
       "      <td>0.062666</td>\n",
       "      <td>0.112375</td>\n",
       "      <td>2013.775751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cbsa_code  Less than high school graduate  \\\n",
       "3  33398.971061                        0.269497   \n",
       "0  30685.978947                        0.144340   \n",
       "1  29970.060729                        0.114530   \n",
       "2  28550.032189                        0.093346   \n",
       "\n",
       "   High school graduate (includes equivalency)  \\\n",
       "3                                     0.264994   \n",
       "0                                     0.348452   \n",
       "1                                     0.288332   \n",
       "2                                     0.231343   \n",
       "\n",
       "   Some college or associate's degree  Bachelor's degree  \\\n",
       "3                            0.295122           0.113690   \n",
       "0                            0.291058           0.140612   \n",
       "1                            0.324709           0.174134   \n",
       "2                            0.278355           0.232685   \n",
       "\n",
       "   Graduate or professional degree  $45,000 to $49,999  $50,000 to $59,999  \\\n",
       "3                         0.056697            0.044216            0.079339   \n",
       "0                         0.075539            0.047049            0.087576   \n",
       "1                         0.098296            0.044449            0.083649   \n",
       "2                         0.164270            0.038647            0.075953   \n",
       "\n",
       "   $60,000 to $74,999  $75,000 to $99,999  ...  \\\n",
       "3            0.099198            0.109377  ...   \n",
       "0            0.106588            0.117062  ...   \n",
       "1            0.105556            0.122861  ...   \n",
       "2            0.100406            0.128104  ...   \n",
       "\n",
       "   Arts, entertainment, and recreation, and accommodation and food services  \\\n",
       "3                                           0.087788                          \n",
       "0                                           0.086827                          \n",
       "1                                           0.104871                          \n",
       "2                                           0.095645                          \n",
       "\n",
       "   Other services, except public administration  Public administration  \\\n",
       "3                                      0.048292               0.060979   \n",
       "0                                      0.048043               0.042181   \n",
       "1                                      0.048654               0.055638   \n",
       "2                                      0.046582               0.048712   \n",
       "\n",
       "   Management, business, science, and arts occupations  Service occupations  \\\n",
       "3                                           0.267799               0.199264   \n",
       "0                                           0.304924               0.173913   \n",
       "1                                           0.345032               0.189879   \n",
       "2                                           0.428895               0.171657   \n",
       "\n",
       "   Sales and office occupations  \\\n",
       "3                      0.233179   \n",
       "0                      0.246849   \n",
       "1                      0.246689   \n",
       "2                      0.224407   \n",
       "\n",
       "   Natural resources, construction, and maintenance occupations  \\\n",
       "3                                           0.135198              \n",
       "0                                           0.042133              \n",
       "1                                           0.081240              \n",
       "2                                           0.062666              \n",
       "\n",
       "   Production, transportation, and material moving occupations         year  \\\n",
       "3                                           0.164559            2012.446945   \n",
       "0                                           0.232181            2009.835789   \n",
       "1                                           0.137159            2013.106275   \n",
       "2                                           0.112375            2013.775751   \n",
       "\n",
       "   cluster  \n",
       "3      3.0  \n",
       "0      1.0  \n",
       "1      2.0  \n",
       "2      0.0  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.DataFrame()\n",
    "for clus in census['cluster'].unique():\n",
    "    new_row = dict()\n",
    "    cluster_census = census[census['cluster'] == clus]\n",
    "    for col in cluster_census:\n",
    "        new_row[col] = cluster_census[col].mean()\n",
    "        \n",
    "    cluster_info = cluster_info.append(new_row, ignore_index=True)\n",
    "    \n",
    "    \n",
    "cluster_info.sort_values([\"Graduate or professional degree\"], inplace=True, axis=0)\n",
    "cluster_info.drop(columns=['cbsa_code', 'year']).to_csv('census_cluster_info.csv', index=True)\n",
    "census_clusters = list(cluster_info['cluster'])\n",
    "print(census_clusters)\n",
    "cluster_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d604117-16c1-4f3d-90bf-bdc62142709f",
   "metadata": {},
   "source": [
    "### Re-map with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "d16192d6-cffd-4458-bcef-081c38bd7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_encode(cluster_num, data, census_code, aqi_code):    \n",
    "    if data == 'aqi':\n",
    "        return aqi_code.index(cluster_num)\n",
    "    elif data == 'census':\n",
    "        return census_code.index(cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "256e74b9-49ad-40e6-ad7c-bfafebd71450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap cluster labels\n",
    "aqi['cluster'] = [cluster_encode(i, 'aqi', census_clusters, aqi_clusters) for i in aqi['cluster']]\n",
    "census['cluster'] = [cluster_encode(i, 'census', census_clusters, aqi_clusters) for i in census['cluster']]\n",
    " \n",
    "# Store files\n",
    "aqi.to_csv('../dataset/aqi_clustered.csv', index=False)\n",
    "census.to_csv('../dataset/census_clustered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "8b386323-f398-42ae-aaf0-551f354bbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification data\n",
    "aqi.sort_values([\"cbsa_code\", 'year'], inplace=True, axis=0)\n",
    "census.sort_values([\"cbsa_code\", 'year'], inplace=True, axis=0)\n",
    "classification_data = census.drop(columns=['cluster'])\n",
    "target_list=list()\n",
    "for year, cbsa in zip(census['year'], census['cbsa_code']):\n",
    "    cluster_val = aqi[(aqi['year'] == year) & (aqi['cbsa_code'] == cbsa)]['cluster']\n",
    "    target_list.append(list(cluster_val)[0] if cluster_val.shape[0] != 0 else None)\n",
    "\n",
    "classification_data['aqi_cluster'] = target_list\n",
    "classification_data = classification_data.dropna(axis=0)\n",
    "classification_data.to_csv('../dataset/classification_census_aqi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092f82d-ae2f-4a4f-a3c8-8c0a63475f22",
   "metadata": {},
   "source": [
    "### Encode Clusters with appropriate values and Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "fe10c78f-5088-481c-a800-a7a15d73ef66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5085, 4)\n",
      "339\n"
     ]
    }
   ],
   "source": [
    "cluster_df = pd.DataFrame()\n",
    "# Create rows for all years and cbsa\n",
    "for year in range(2005, 2020):\n",
    "    for code in common_cbsa:\n",
    "        #define new row\n",
    "        new_row = {'year': year,\n",
    "                   'cbsa_code': code}\n",
    "        \n",
    "        #find the rows that match the year and cbsa\n",
    "        curr_census = census[(census['year'] == year) & (census['cbsa_code'] == code)] \n",
    "        new_row['census_cluster'] = cluster_encode(list(curr_census['cluster'])[0], 'census', census_clusters, aqi_clusters) if curr_census.shape[0] == 1 else None\n",
    "        curr_aqi = aqi[(aqi['year'] == year) & (aqi['cbsa_code'] == code)]\n",
    "        new_row['aqi_cluster'] = cluster_encode(list(curr_aqi['cluster'])[0], 'aqi', census_clusters, aqi_clusters) if curr_aqi.shape[0] == 1 else None\n",
    "        \n",
    "        # add new row \n",
    "        cluster_df = cluster_df.append(new_row, ignore_index=True)\n",
    "        \n",
    "    #Impute missing values\n",
    "    cluster_df = cluster_df.fillna(method='bfill', axis=0, limit=3)\n",
    "    cluster_df = cluster_df.fillna(method='ffill', axis=0)\n",
    "\n",
    "cluster_df.sort_values(['cbsa_code', 'year'], inplace=True, axis=0) #sort the values\n",
    "print(cluster_df.shape)\n",
    "print(len(cluster_df['cbsa_code'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "6a007052-3919-4051-b6ef-c987786f3b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    2161\n",
       "1.0    1610\n",
       "0.0     985\n",
       "3.0     329\n",
       "Name: census_cluster, dtype: int64"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df['census_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff463f-3c8a-4813-8698-3ff8bc52db05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "9d4325bb-6b9b-409d-840c-f4cf46b2b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time lagged cross correlation\n",
    "def crosscorr(datax, datay, lag=0):\n",
    "    return datax.corr(datay.shift(lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "6b4437df-6ca4-4f13-9f73-0de6272d272a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-12: -0.10944911182523068,\n",
       " 0: -0.05584289874824906,\n",
       " -1: -0.05346083025729985,\n",
       " -2: -0.03711440486393873,\n",
       " -3: -0.025167158136947972,\n",
       " -8: -0.02359547731440106,\n",
       " 1: -0.00801163102247162,\n",
       " -7: 0.0018827729177159067,\n",
       " 11: 0.004333963228612672,\n",
       " 2: 0.008531242552786858,\n",
       " -4: 0.013128928991209935,\n",
       " 4: 0.032964785181387436,\n",
       " 3: 0.036536714175916966,\n",
       " 6: 0.04171901451232487,\n",
       " -6: 0.05614317349986724,\n",
       " 5: 0.056258837352246134,\n",
       " -9: 0.07246682467532133,\n",
       " 7: 0.0788699124638912,\n",
       " 10: 0.08017705969524414,\n",
       " -5: 0.08265724669669477,\n",
       " 8: 0.08617687191848714,\n",
       " -10: 0.12669421717966722,\n",
       " -11: 0.1274501582662226,\n",
       " 9: 0.14795070936148344,\n",
       " 12: 0.28372859640123027,\n",
       " -13: 0.42857142857142855}"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_corr = dict()\n",
    "for lag in range(-13, 13):\n",
    "    correlation = dict()\n",
    "    for cbsa in common_cbsa:\n",
    "        df = cluster_df[cluster_df['cbsa_code'] == cbsa].drop(columns=['cbsa_code', 'year'])\n",
    "\n",
    "        correlation[cbsa] = crosscorr( df['aqi_cluster'], df['census_cluster'], lag)\n",
    "    \n",
    "    lag_corr[lag] = mean([i for i in correlation.values() if not math.isnan(i)])\n",
    "    \n",
    "lag_corr = {k:v for k,v in sorted(lag_corr.items(), key=lambda item:item[1])}\n",
    "lag_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "7d034f92-df13-4ce7-92d3-0d119d4b0be0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "bdd90269-12ee-4ac1-a63f-53d24dab8d56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.224188790560472"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = dict()\n",
    "for cbsa in common_cbsa:\n",
    "    df = cluster_df[cluster_df['cbsa_code'] == cbsa]\n",
    "    \n",
    "    distance, path = fastdtw(df['census_cluster'], df['aqi_cluster'])\n",
    "    similarity[cbsa] = distance\n",
    "mean([i for i in similarity.values() if not math.isnan(i)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "ac624d27-a9c0-4df4-90bc-5b6b263ed0e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12731013367534358"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "covariance = dict()\n",
    "for cbsa in common_cbsa:\n",
    "    df = cluster_df[cluster_df['cbsa_code'] == cbsa].drop(columns=['cbsa_code', 'year'])\n",
    "    \n",
    "    covariance[cbsa], _ = spearmanr(df['census_cluster'], df['aqi_cluster'])\n",
    "    \n",
    "mean([i for i in covariance.values() if not math.isnan(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20519a-3b0e-404e-b742-e17a2a3e397f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cluster Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "97fd9905-dd86-4079-ac30-9b915480602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_info.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "55276634-2b71-4deb-85d8-68257a0258f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0, 1.0, 4.0, 3.0, 0.0],\n",
       " [2.0, 0.0, 4.0, 1.0, 3.0],\n",
       " [2.0, 3.0, 0.0, 4.0, 1.0],\n",
       " [0.0, 3.0, 1.0, 4.0, 2.0],\n",
       " [2.0, 1.0, 0.0, 4.0, 3.0],\n",
       " [2.0, 0.0, 1.0, 4.0, 3.0],\n",
       " [0.0, 2.0, 1.0, 4.0, 3.0],\n",
       " [0.0, 3.0, 4.0, 1.0, 2.0],\n",
       " [3.0, 0.0, 4.0, 1.0, 2.0],\n",
       " [3.0, 4.0, 0.0, 1.0, 2.0],\n",
       " [2.0, 4.0, 3.0, 1.0, 0.0],\n",
       " [2.0, 3.0, 1.0, 0.0, 4.0],\n",
       " [0.0, 2.0, 4.0, 1.0, 3.0],\n",
       " [2.0, 1.0, 3.0, 4.0, 0.0],\n",
       " [2.0, 0.0, 3.0, 4.0, 1.0],\n",
       " [2.0, 4.0, 1.0, 3.0, 0.0],\n",
       " [0.0, 3.0, 1.0, 2.0, 4.0],\n",
       " [3.0, 0.0, 1.0, 4.0, 2.0],\n",
       " [0.0, 4.0, 3.0, 1.0, 2.0],\n",
       " [3.0, 0.0, 4.0, 2.0, 1.0],\n",
       " [2.0, 3.0, 4.0, 0.0, 1.0],\n",
       " [3.0, 2.0, 4.0, 1.0, 0.0],\n",
       " [2.0, 3.0, 4.0, 1.0, 0.0],\n",
       " [2.0, 0.0, 3.0, 1.0, 4.0],\n",
       " [4.0, 3.0, 2.0, 1.0, 0.0],\n",
       " [4.0, 3.0, 0.0, 2.0, 1.0],\n",
       " [0.0, 1.0, 2.0, 3.0, 4.0]]"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_order = list()\n",
    "for col in cluster_info.columns:\n",
    "    cluster_info.sort_values([col], inplace=True, axis=0)\n",
    "       \n",
    "    if list(cluster_info['cluster'].copy()) not in cluster_order:\n",
    "        cluster_order.append(list(cluster_info['cluster'].copy()))\n",
    "    \n",
    "cluster_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71742a21-31a0-4e95-8670-3af4f5224884",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "de2a921f-651d-486a-894e-3a2ba8fab626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def k_fold_validate(folds, model, features, target, model_type, output=True):\n",
    "    kf = model_selection.KFold(n_splits=folds, shuffle=True, random_state=3)\n",
    "    \n",
    "    rec, prec, f1 = [], [], []\n",
    "    imp_df = pd.DataFrame()\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        # Retrieve the train and test sets\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        # Standardize the data to optimize performance\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        rec += [metrics.recall_score(y_pred, y_test, average='weighted')]\n",
    "        prec += [metrics.precision_score(y_pred, y_test, average='weighted')]\n",
    "        f1 += [metrics.f1_score(y_pred, y_test, average='weighted')]\n",
    "        \n",
    "        # Store the feature importances for the fold\n",
    "        if model_type == 'lrm':\n",
    "            imps = abs(model.coef_[0])\n",
    "        elif model_type == 'dtm' or model_type == 'rfm':\n",
    "            imps = model.feature_importances_\n",
    "        elif model_type == 'nbm':\n",
    "            imps = inspection.permutation_importance(model, X_test, y_test).importances_mean\n",
    "          \n",
    "        imps = {k:v for k,v in enumerate(imps)}\n",
    "        imp_df = imp_df.append(imps, ignore_index=True)\n",
    "        \n",
    "    if output:\n",
    "        print(\"recall    = {:.4f} ±{:.4f} {}\".format(np.mean(rec), np.std(rec), rec))\n",
    "        print(\"precision = {:.4f} ±{:.4f} {}\".format(np.mean(prec), np.std(prec), prec))\n",
    "        print(\"f1        = {:.4f} ±{:.4f} {}\".format(np.mean(f1), np.std(f1), f1))\n",
    "    \n",
    "    scores = {'recall': [np.mean(rec), np.std(rec)],\n",
    "              'precision': [np.mean(prec), np.std(prec)],\n",
    "              'f1': [np.mean(f1), np.std(f1)],\n",
    "              'feature_ranks': {k:v for k, v in enumerate(imp_df.mean(axis=0))}            \n",
    "             }        \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "1e6de599-637c-4b23-8482-6d1504e05491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and target \n",
    "X = census.drop(columns=['cluster'])\n",
    "target = 'aqi_cluster'\n",
    "y = cluster_df[[target, 'year', 'cbsa_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "c20d7383-b0d2-4652-b826-d7971de8ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create rows for all years and cbsa\n",
    "for year in range(2005, 2020):\n",
    "    for code in common_cbsa:\n",
    "        #define new row\n",
    "        new_row = {'year': year,\n",
    "                   'cbsa_code': code}\n",
    "        \n",
    "        \n",
    "        #find the rows that match the year and cbsa\n",
    "        curr_census = X[(X['year'] == year) & (X['cbsa_code'] == code)] \n",
    "        if curr_census.shape[0] == 0:\n",
    "            new_row.update({k:None for k in X.columns})\n",
    "            X = X.append(new_row, ignore_index=True)\n",
    "            \n",
    "        curr_aqi = y[(y['year'] == year) & (y['cbsa_code'] == code)]\n",
    "        if curr_aqi.shape[0] == 0:\n",
    "            new_row[target] = None\n",
    "            y = y.append(new_row, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    # #Impute missing values\n",
    "    # cluster_df = cluster_df.fillna(method='bfill', axis=1, limit=3)\n",
    "    # cluster_df = cluster_df.fillna(method='ffill', axis=1)\n",
    "\n",
    "X.sort_values(['cbsa_code', 'year'], inplace=True, axis=0) #sort the values\n",
    "y.sort_values(['cbsa_code', 'year'], inplace=True, axis=0) #sort the values\n",
    "\n",
    "data = X.copy()\n",
    "data[target] = y[target]\n",
    "\n",
    "# Drop na values\n",
    "data = data.dropna()\n",
    "\n",
    "# Drop irrelevant columns\n",
    "X = data.drop(columns=['year', target])\n",
    "y = data[target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "b8764dff-859e-4957-ac78-3abf940ad27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4644, 32)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "adfec934-18ad-47d0-8302-b64e52bc9fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    2102\n",
       "1.0    1605\n",
       "0.0     500\n",
       "2.0     413\n",
       "4.0      24\n",
       "Name: aqi_cluster, dtype: int64"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "cfea1878-c5e4-4a06-ac54-b35340b5ecfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27784/2547908017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Small Dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlrm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlrm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlrm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1514\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m         )\n\u001b[1;32m-> 1516\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1517\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;34m\"multilabel-sequences\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     ]:\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.3, random_state=17, shuffle=True)\n",
    "# Small Dataset\n",
    "lrm = LogisticRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "lrm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7978e4-540a-4f60-98f0-327510377446",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "d760b155-ca75-4c85-95a1-e4935be3cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall    = 0.3553 ±0.0141 [0.34660925726587727, 0.3326157158234661, 0.37029063509149623, 0.35844994617868675, 0.36853448275862066]\n",
      "precision = 0.3514 ±0.0104 [0.34964910790631365, 0.3334426909842384, 0.36476715457681336, 0.35135074668437277, 0.357609714516184]\n",
      "f1        = 0.3529 ±0.0121 [0.3478227805070351, 0.33260934531060743, 0.3673406687368896, 0.35468095488785667, 0.36229428007212]\n"
     ]
    }
   ],
   "source": [
    "# Small Dataset\n",
    "dtm = DecisionTreeClassifier()\n",
    "scores = k_fold_validate(5, dtm, X, y, 'dtm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9205a-5a19-4521-930e-aec074ee940f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d197648f-26bf-4b3e-83bb-e0b262f0c70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall    = 0.1099 ±0.0321 [0.08536585365853659, 0.07608695652173914, 0.16666666666666666, 0.12048192771084337, 0.10112359550561797]\n",
      "precision = 0.1040 ±0.0148 [0.08235294117647059, 0.08974358974358974, 0.11458333333333333, 0.11627906976744186, 0.11688311688311688]\n",
      "f1        = 0.1058 ±0.0205 [0.08383233532934131, 0.08235294117647059, 0.13580246913580246, 0.1183431952662722, 0.10843373493975904]\n"
     ]
    }
   ],
   "source": [
    "# Small Dataset\n",
    "rfm = RandomForestClassifier()\n",
    "scores = k_fold_validate(5, rfm, Xs, ys, 'rfm')\n",
    "og_small_score['rfm'] = scores['f1'][0]\n",
    "imp_small = imp_small.append(scores['feature_ranks'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77de08d-98f5-4085-b08c-19ac3657c41f",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6eea505b-08be-476c-bee8-a447a3b65c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall    = 0.3375 ±0.1281 [0.45454545454545453, 0.14285714285714285, 0.49206349206349204, 0.34146341463414637, 0.2564102564102564]\n",
      "precision = 0.3783 ±0.2863 [0.7647058823529411, 0.02564102564102564, 0.6458333333333334, 0.32558139534883723, 0.12987012987012986]\n",
      "f1        = 0.3356 ±0.2082 [0.5701754385964911, 0.043478260869565216, 0.5585585585585586, 0.33333333333333337, 0.17241379310344826]\n"
     ]
    }
   ],
   "source": [
    "# Small Dataset\n",
    "nbm = GaussianNB()\n",
    "scores = k_fold_validate(5, nbm, Xs, ys, 'nbm')\n",
    "og_small_score['nbm'] = scores['f1'][0]\n",
    "imp_small = imp_small.append(scores['feature_ranks'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362436-ca6b-4a98-be54-a47c9b2f4514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
